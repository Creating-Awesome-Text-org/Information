# Method and Model Possibilities

This files lists the various methods and model possibilities for the proposed Creating Awesome Text Aims:

### OpenAI with Local Information 
The core concept is to use existing generative AI models created by OpenAI such as the ChatGPT models through an API key. 
What makes this incredibly powerful is the ability to leverage local files (pdf, word, csv) to create an existing knowledge base
of information on which the model can act. 
However, this means that ChatGPT comes into contact with data sources. 
The following link shows OpenAI's privacy policy [https://openai.com/policies/privacy-policy](https://openai.com/policies/privacy-policy).
In summary, OpenAI collects Account Information, User Content (File uploads),  Communication Information, and Social Media Interaction. 
However, it is **important** to note that OpenAI's models are not trained on the output or inputs to the models. 
The link stating this is as follows: [https://openai.com/api-data-privacy](https://openai.com/api-data-privacy).

#### Tools
LangChain presents an optimal framework in which to work with OpenAI and its LLM models. 
[https://python.langchain.com/docs/get_started/introduction.html](https://python.langchain.com/docs/get_started/introduction.html)

#### Why
OpenAI is dominating the LLM race at this current point in time. They have invested millions and have some brightest minds working on 
the models such as ChatGPT. There does not exist a better LLM generative model more capable that ChatGPT today.
Additionally, its knowledge base is massive encompassing unique topics of which existing knowledge may benefit interactions. 

However, there exists three drawbacks: 
1. Financial Cost of OpenAI account and use of ChatGPT models. The language model pricing can be accesses at [https://openai.com/pricing](https://openai.com/pricing)
2. No fine-tuning on existing documentation, however the complexity and capability of ChatGOT may render this a null point. 
3. Data privacy is compromised even if not used to train OpenAI models.

#### Tutorials
- [Use Your Locally Stored Files To Get Response From GPT - OpenAI | Langchain | Python](https://youtu.be/NC1Ni9KS-rk?si=kFklvimKPrXVfcYy)
- [Query Your Data with GPT-4 | Embeddings, Vector Databases | Langchain JS Knowledgebase](https://youtu.be/jRnUPUTkZmU?si=Jn3xJ_QxXcsum87r)
- [Using ChatGPT with YOUR OWN Data. This is magical. (LangChain OpenAI API)](https://youtu.be/9AXP7tCI9PI?si=JHWz1gXPsrirzkx2)
- [Create Your Own ChatGPT with PDF Data in 5 Minutes (LangChain Tutorial)](https://youtu.be/au2WVVGUvc8?si=zIr2_AOj_-BUwIrL)


### Private GPT
Private GPT aims to retain 100% privacy, allowing for the use of a GPT like model locally on your device. 
The project has capability to ingest documents for use by the model.

#### Tools
- [LangChain](https://github.com/hwchase17/langchain) 
- [GPT4All](https://github.com/nomic-ai/gpt4all)
- [LlamaCpp](https://github.com/ggerganov/llama.cpp)
- [Chroma](https://www.trychroma.com/)
- [Sentence Transformers](https://www.sbert.net/)

#### Why
This is a locally run LLM model. Data is not transmitted, as such the use of this model would retain 100% data privacy and protection. 
Additionally, this model is trending on GitHub and is written is a package style such that it appears to be great to work with, 
and it backed up by the GitHub community. 

However, the LLM models used are not up to the standard of models trained by OpenAI 
due to the vast resource and computational constraints. 

#### Tutorials
- [PrivateGPT: Chat to your FILES OFFLINE and FREE [Installation and Tutorial]](https://youtu.be/G7iLllmx4qc?si=GUDO7cCLt2KMgS0m)


### Fine Tune Existing Model
Use existing pre-trained HuggingFace models are fine-tune them on a dataset comprised on the author's historical texts, 
with the aim of creating a LLM model capable of mimicking the user's style of writing, as well as training the model on the 
information within the dataset. 

Tools:
- [HuggingFace](https://huggingface.co/)

HuggingFace provides extensive tutorials on preparing the dataset, forming the dataset and fine tuning an existing model

#### Why
The above proposal's do not deal with training/ fine-tuning an existing model,
but rather use their existing capabilities to use the provided information to mimic or answer questions about 
the provided information. 

This proposal, would fine-tune a pre-trained model on the data generated by the Author.
The proposed model would be trained to mimic the writing style, spelling, grammar, etc of the author.

However, this proposal requires the following considerations:
- Fine-tuning the model on only the author's data could introduce bias in terms of spelling, facts, etc. which may be incorrect
- The quantity of data provided by the author may not be sufficient for fine-tuning purposes.
- Fine-tuning the model would require training on a GPU processor. This is not a simple process and can be quite tricky to get working correctly.
- The use of the stand-alone model would require integrating it into the specific use-cases.


#### Tutorials and Information
- [HuggingFace Transformers Information](https://huggingface.co/docs/transformers/index)
- [Dataset Pre-processing](https://huggingface.co/docs/transformers/preprocessing)
- [Fine-tuning Pre-trained Model](https://huggingface.co/docs/transformers/training)


#### Existing Models
- [HuggingFace leaderboard of LLM and Chatbot models](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
- [LlaMa Models Overview](https://huggingface.co/docs/transformers/main/model_doc/llama)
  - LlaMa Models are showing great promise in text generation.
- [Hugging Face Text Generation Models](https://huggingface.co/models?pipeline_tag=text-generation&sort=trending)


## Interesting Finds
### LangChain for Data Analysis
This tutorial introduces and uses existing Language models to query Pandas dataframes for information. 
This may be of use in understanding user data and feedback, allowing for language query of numerical, ordinal, nominal and text response data. 
This may benefit data analysis of [Flourishing Humanity Corporation](https://flourishinghumanitycorporation.com/). 
Depending on its usage data privacy may be a top-consideration of use in such an application.

- Tutorial Link: [https://youtu.be/rFQ5Kmkd4jc?si=RDWKOeK8uedAw7Cf](https://youtu.be/rFQ5Kmkd4jc?si=RDWKOeK8uedAw7Cf)

The proposed tutorial makes use of the LangChain tool and OpenAI Key.


### Summarize and Query PDF
The below tutorial has directly applicability in summarizing PDF documents such as research papers, 
and providing summaries and query capabilities. 
This may be a useful capability to summarize several research papers quickly with the capability of further query.

- Tutorial Link: https://www.youtube.com/watch?v=p_MQRWH5Y6k

The proposed tutorial makes use of the LangChain tool and OpenAI Key

### Thoughts
- Existing packages such as LangChain allow for the simplification of using LLM models by providing already developed capabilities to interact 
with multiple types of documents and how the output from the models can be used.
- PrivateGPT was constructed using LangChain and GPT4All. The tutorials provided in the first option
**Open AI with local information** could potentially be transmitted to a local model maintaining privacy.